{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ooTIJVCs_8rB"
   },
   "source": [
    "<h2> CNN with 1 Convolutional Layer - Dropout to Reduce Overfitting </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lgrBrH8pL383"
   },
   "source": [
    "<p>Overfitting is a problem in Deep Neural Networks (DNN): the model learns to classify only the training set, adapting itself to the training examples instead of learning decision boundaries capable of classifying generic instances. </p>\n",
    "<a>https://pgaleone.eu/deep-learning/regularization/2017/01/10/anaysis-of-dropout/</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2314,
     "status": "ok",
     "timestamp": 1569754434803,
     "user": {
      "displayName": "D Meirong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDiaGPg7iox3RNjLk5fsQm8ZIF3UAOud5pIvPtjyg=s64",
      "userId": "16646563330135327635"
     },
     "user_tz": -480
    },
    "id": "_-Z1ogte_oBF",
    "outputId": "196863ab-5d6a-4216-d1ae-b4ec9fc003c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import add, concatenate, Conv2D, Dense, Dropout, Flatten, Input\n",
    "from tensorflow.keras.layers import Activation, AveragePooling2D, BatchNormalization, MaxPooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2299,
     "status": "ok",
     "timestamp": 1569754434804,
     "user": {
      "displayName": "D Meirong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDiaGPg7iox3RNjLk5fsQm8ZIF3UAOud5pIvPtjyg=s64",
      "userId": "16646563330135327635"
     },
     "user_tz": -480
    },
    "id": "Exz2zGJ0AEGD",
    "outputId": "f91bc9c7-070a-497f-9d9f-a1e47222fd0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nEFDz4iPAlE2"
   },
   "outputs": [],
   "source": [
    "root_path = 'gdrive/My Drive/Colab Notebooks/'  #change dir to your project folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4283,
     "status": "ok",
     "timestamp": 1569754436825,
     "user": {
      "displayName": "D Meirong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDiaGPg7iox3RNjLk5fsQm8ZIF3UAOud5pIvPtjyg=s64",
      "userId": "16646563330135327635"
     },
     "user_tz": -480
    },
    "id": "4i6v4kSgApZF",
    "outputId": "c9866119-1c96-4664-b48c-dafda4231d30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the training and test datasets:\n",
      "The shapes are (4264, 224, 224, 3), (4264,), (1067, 224, 224, 3), (1067,)\n"
     ]
    }
   ],
   "source": [
    "trDatOrg       = np.load(root_path + 'Flower_Power/flrnonflr-train-imgs224-0.8.npz')['arr_0']\n",
    "trLblOrg       = np.load(root_path + 'Flower_Power/flrnonflr-train-labels224-0.8.npz')['arr_0']\n",
    "tsDatOrg       = np.load(root_path + 'Flower_Power/flrnonflr-test-imgs224-0.8.npz')['arr_0']\n",
    "tsLblOrg       = np.load(root_path + 'Flower_Power/flrnonflr-test-labels224-0.8.npz')['arr_0']\n",
    "\n",
    "print(\"For the training and test datasets:\")\n",
    "print(\"The shapes are %s, %s, %s, %s\" \\\n",
    "      %(trDatOrg.shape, trLblOrg.shape, tsDatOrg.shape, tsLblOrg.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "18IbJqrLZn-HHb-whzyCRisXiPGdfj0tW"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13269,
     "status": "ok",
     "timestamp": 1569754445825,
     "user": {
      "displayName": "D Meirong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDiaGPg7iox3RNjLk5fsQm8ZIF3UAOud5pIvPtjyg=s64",
      "userId": "16646563330135327635"
     },
     "user_tz": -480
    },
    "id": "qjEc01oBCtRw",
    "outputId": "581cc8ef-6f35-4448-c885-e7f8dd929782"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Randomly show 10 examples of the images\n",
    "\n",
    "data = tsDatOrg\n",
    "label = tsLblOrg\n",
    "\n",
    "for i in range(20):\n",
    "    index = random.randint(0, len(data)-1)\n",
    "    print(\"Showing %s index image, It is %s\" %(index, label[index]))\n",
    "    imgplot = plt.imshow(data[index])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mn3krgBCC7kc"
   },
   "outputs": [],
   "source": [
    "# Convert the data into 'float32'\n",
    "# Rescale the values from 0~255 to 0~1\n",
    "trDat       = trDatOrg.astype('float32')/255\n",
    "tsDat       = tsDatOrg.astype('float32')/255\n",
    "\n",
    "# Retrieve the row size of each image\n",
    "# Retrieve the column size of each image\n",
    "imgrows     = trDat.shape[1]\n",
    "imgclms     = trDat.shape[2]\n",
    "channel     = 3\n",
    "\n",
    "# Perform one hot encoding on the labels\n",
    "# Retrieve the number of classes in this problem\n",
    "trLbl       = to_categorical(trLblOrg)\n",
    "tsLbl       = to_categorical(tsLblOrg)\n",
    "num_classes = tsLbl.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fpo1pk4FHEVV"
   },
   "outputs": [],
   "source": [
    "# Split original training data to sub-training (90%) and validation data (10%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(trDat, trLbl, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9t3ISbl3JOSl"
   },
   "outputs": [],
   "source": [
    "# X_test forms the test images, and y_test forms the test labels\n",
    "X_test = tsDat \n",
    "y_test = tsLbl \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MFNlWAt6DrT7"
   },
   "source": [
    "<h2> Define Model </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MBnssrsNES2s"
   },
   "source": [
    "<p>The 1st layer is a Conv2D layer for the convolution operation that extracts features from the input images by sliding a convolution filter over the input to produce a feature map. Here I choose feature map with size 3 x 3.\n",
    "  \n",
    "The 2nd layer is a MaxPooling2D layer for the max-pooling operation that reduces the dimensionality of each feature, which helps shorten training time and reduce number of parameters. Here I choose the pooling window with size 2 x 2.\n",
    "  \n",
    "The next step is to feed the last output tensor into a stack of Dense layers, otherwise known as fully-connected layers. These densely connected classifiers process vectors, which are 1D, whereas the current output is a 3D tensor. Thus, I need to flatten the 3D outputs to 1D, and then add 2 Dense layers on top.\n",
    "  \n",
    "I do a 2-way classification (as there are flowers and non-flowers), using a final layer with 2 outputs and a softmax activation. Softmax activation enables me to calculate the output based on the probabilities. Each class is assigned a probability and the class with the maximum probability is the modelâ€™s output for the input. <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1248,
     "status": "ok",
     "timestamp": 1569757403782,
     "user": {
      "displayName": "D Meirong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDiaGPg7iox3RNjLk5fsQm8ZIF3UAOud5pIvPtjyg=s64",
      "userId": "16646563330135327635"
     },
     "user_tz": -480
    },
    "id": "nYeOqn1VvUUD",
    "outputId": "88d419f2-0605-4c1d-f3a0-6126c79ff699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 401408)            0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 128)               51380352  \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 51,389,634\n",
      "Trainable params: 51,389,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def createBaseModel():\n",
    "  inputs = Input(shape=(imgrows, imgclms, channel))\n",
    "  x = Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
    "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "  \n",
    "  x = Flatten()(x)\n",
    "  \n",
    "  x = Dense(128, activation='relu')(x)\n",
    "  x = Dropout(0.3)(x)\n",
    "  x = Dense(64, activation='relu')(x)\n",
    "  x = Dense(num_classes, activation='softmax')(x)\n",
    "  \n",
    "  model = Model(inputs=[inputs],outputs=x)\n",
    "  \n",
    "  model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "  \n",
    "model = createBaseModel()\n",
    "modelGo = createBaseModel()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hm0keHs1MZSj"
   },
   "source": [
    "<h2> Training the Model </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tCF00XhPMdHt"
   },
   "source": [
    "<p>I train the model with batch size of 32 and 20 epochs on both training and validation data. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 746
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 157543,
     "status": "ok",
     "timestamp": 1569756086856,
     "user": {
      "displayName": "D Meirong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDiaGPg7iox3RNjLk5fsQm8ZIF3UAOud5pIvPtjyg=s64",
      "userId": "16646563330135327635"
     },
     "user_tz": -480
    },
    "id": "9cORbjzKMI_F",
    "outputId": "08e6742b-22c8-45ee-ce7a-c11920eccb0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3837 samples, validate on 427 samples\n",
      "Epoch 1/20\n",
      "3837/3837 [==============================] - 8s 2ms/sample - loss: 0.0018 - acc: 0.9997 - val_loss: 1.0379 - val_acc: 0.8454\n",
      "Epoch 2/20\n",
      "3837/3837 [==============================] - 8s 2ms/sample - loss: 0.0011 - acc: 0.9997 - val_loss: 1.2917 - val_acc: 0.8478\n",
      "Epoch 3/20\n",
      "3837/3837 [==============================] - 8s 2ms/sample - loss: 6.9338e-04 - acc: 0.9997 - val_loss: 1.4994 - val_acc: 0.8009\n",
      "Epoch 4/20\n",
      "3837/3837 [==============================] - 8s 2ms/sample - loss: 0.0213 - acc: 0.9922 - val_loss: 1.1388 - val_acc: 0.8244\n",
      "Epoch 5/20\n",
      "3837/3837 [==============================] - 8s 2ms/sample - loss: 0.0014 - acc: 0.9997 - val_loss: 1.2801 - val_acc: 0.8361\n",
      "Epoch 6/20\n",
      "3837/3837 [==============================] - 8s 2ms/sample - loss: 0.0094 - acc: 0.9966 - val_loss: 1.2807 - val_acc: 0.7845\n",
      "Epoch 7/20\n",
      "3837/3837 [==============================] - 8s 2ms/sample - loss: 0.0133 - acc: 0.9969 - val_loss: 1.1451 - val_acc: 0.8267\n",
      "Epoch 8/20\n",
      "3837/3837 [==============================] - 8s 2ms/sample - loss: 0.0349 - acc: 0.9906 - val_loss: 1.3642 - val_acc: 0.8009\n",
      "Epoch 9/20\n",
      "3837/3837 [==============================] - 8s 2ms/sample - loss: 0.0198 - acc: 0.9935 - val_loss: 1.0059 - val_acc: 0.8080\n",
      "Epoch 10/20\n",
      "3837/3837 [==============================] - 8s 2ms/sample - loss: 0.0069 - acc: 0.9977 - val_loss: 1.4373 - val_acc: 0.8056\n",
      "Epoch 11/20\n",
      "3837/3837 [==============================] - 8s 2ms/sample - loss: 0.0048 - acc: 0.9982 - val_loss: 1.5791 - val_acc: 0.8009\n",
      "Epoch 12/20\n",
      "3837/3837 [==============================] - 8s 2ms/sample - loss: 0.0049 - acc: 0.9984 - val_loss: 1.5059 - val_acc: 0.8126\n",
      "Epoch 13/20\n",
      "3837/3837 [==============================] - 8s 2ms/sample - loss: 0.0015 - acc: 0.9997 - val_loss: 1.4600 - val_acc: 0.8126\n",
      "Epoch 14/20\n",
      "3837/3837 [==============================] - 8s 2ms/sample - loss: 3.6016e-04 - acc: 1.0000 - val_loss: 1.5940 - val_acc: 0.8126\n",
      "Epoch 15/20\n",
      "3837/3837 [==============================] - 8s 2ms/sample - loss: 3.2738e-04 - acc: 1.0000 - val_loss: 1.6464 - val_acc: 0.8150\n",
      "Epoch 16/20\n",
      "3837/3837 [==============================] - 8s 2ms/sample - loss: 3.3857e-04 - acc: 1.0000 - val_loss: 1.6376 - val_acc: 0.8197\n",
      "Epoch 17/20\n",
      "3837/3837 [==============================] - 8s 2ms/sample - loss: 1.3486e-04 - acc: 1.0000 - val_loss: 1.6772 - val_acc: 0.8150\n",
      "Epoch 18/20\n",
      "3837/3837 [==============================] - 8s 2ms/sample - loss: 1.2361e-04 - acc: 1.0000 - val_loss: 1.7536 - val_acc: 0.8103\n",
      "Epoch 19/20\n",
      "3837/3837 [==============================] - 8s 2ms/sample - loss: 0.0097 - acc: 0.9974 - val_loss: 1.4953 - val_acc: 0.7939\n",
      "Epoch 20/20\n",
      "3837/3837 [==============================] - 8s 2ms/sample - loss: 0.0024 - acc: 0.9995 - val_loss: 1.3515 - val_acc: 0.8056\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "# This is where the training starts\n",
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2926,
     "status": "ok",
     "timestamp": 1569756107898,
     "user": {
      "displayName": "D Meirong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDiaGPg7iox3RNjLk5fsQm8ZIF3UAOud5pIvPtjyg=s64",
      "userId": "16646563330135327635"
     },
     "user_tz": -480
    },
    "id": "BWP12IzdwRsI",
    "outputId": "f8d1cee8-bfe4-4f03-a69c-8830bf6110ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.4607791295091794\n",
      "Test accuracy: 0.82005626\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DRSJT93UvtB0"
   },
   "source": [
    "<p> Batch Size Increment </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 746
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 141180,
     "status": "ok",
     "timestamp": 1569757552764,
     "user": {
      "displayName": "D Meirong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDiaGPg7iox3RNjLk5fsQm8ZIF3UAOud5pIvPtjyg=s64",
      "userId": "16646563330135327635"
     },
     "user_tz": -480
    },
    "id": "QeVss91Bvq7N",
    "outputId": "9e15d9cf-eb88-44b4-b0d1-6c160143de1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3837 samples, validate on 427 samples\n",
      "Epoch 1/20\n",
      "3837/3837 [==============================] - 7s 2ms/sample - loss: 2.3862 - acc: 0.5421 - val_loss: 0.5996 - val_acc: 0.5785\n",
      "Epoch 2/20\n",
      "3837/3837 [==============================] - 7s 2ms/sample - loss: 0.5462 - acc: 0.7389 - val_loss: 0.4508 - val_acc: 0.8220\n",
      "Epoch 3/20\n",
      "3837/3837 [==============================] - 7s 2ms/sample - loss: 0.4126 - acc: 0.8329 - val_loss: 0.3656 - val_acc: 0.8290\n",
      "Epoch 4/20\n",
      "3837/3837 [==============================] - 7s 2ms/sample - loss: 0.3330 - acc: 0.8681 - val_loss: 0.4171 - val_acc: 0.7822\n",
      "Epoch 5/20\n",
      "3837/3837 [==============================] - 7s 2ms/sample - loss: 0.2493 - acc: 0.9064 - val_loss: 0.3338 - val_acc: 0.8525\n",
      "Epoch 6/20\n",
      "3837/3837 [==============================] - 7s 2ms/sample - loss: 0.1659 - acc: 0.9380 - val_loss: 0.3367 - val_acc: 0.8618\n",
      "Epoch 7/20\n",
      "3837/3837 [==============================] - 7s 2ms/sample - loss: 0.1084 - acc: 0.9625 - val_loss: 0.3613 - val_acc: 0.8571\n",
      "Epoch 8/20\n",
      "3837/3837 [==============================] - 7s 2ms/sample - loss: 0.0642 - acc: 0.9810 - val_loss: 0.3749 - val_acc: 0.8618\n",
      "Epoch 9/20\n",
      "3837/3837 [==============================] - 7s 2ms/sample - loss: 0.0418 - acc: 0.9888 - val_loss: 0.6288 - val_acc: 0.8197\n",
      "Epoch 10/20\n",
      "3837/3837 [==============================] - 7s 2ms/sample - loss: 0.0483 - acc: 0.9862 - val_loss: 0.5012 - val_acc: 0.8618\n",
      "Epoch 11/20\n",
      "3837/3837 [==============================] - 7s 2ms/sample - loss: 0.0257 - acc: 0.9935 - val_loss: 0.7473 - val_acc: 0.8478\n",
      "Epoch 12/20\n",
      "3837/3837 [==============================] - 7s 2ms/sample - loss: 0.0247 - acc: 0.9940 - val_loss: 0.5748 - val_acc: 0.8642\n",
      "Epoch 13/20\n",
      "3837/3837 [==============================] - 7s 2ms/sample - loss: 0.0163 - acc: 0.9964 - val_loss: 0.7363 - val_acc: 0.8478\n",
      "Epoch 14/20\n",
      "3837/3837 [==============================] - 7s 2ms/sample - loss: 0.0150 - acc: 0.9956 - val_loss: 0.5806 - val_acc: 0.8642\n",
      "Epoch 15/20\n",
      "3837/3837 [==============================] - 7s 2ms/sample - loss: 0.0184 - acc: 0.9950 - val_loss: 0.7013 - val_acc: 0.8501\n",
      "Epoch 16/20\n",
      "3837/3837 [==============================] - 7s 2ms/sample - loss: 0.0111 - acc: 0.9974 - val_loss: 0.8028 - val_acc: 0.8478\n",
      "Epoch 17/20\n",
      "3837/3837 [==============================] - 7s 2ms/sample - loss: 0.0160 - acc: 0.9956 - val_loss: 0.6848 - val_acc: 0.8525\n",
      "Epoch 18/20\n",
      "3837/3837 [==============================] - 7s 2ms/sample - loss: 0.0079 - acc: 0.9987 - val_loss: 0.7882 - val_acc: 0.8548\n",
      "Epoch 19/20\n",
      "3837/3837 [==============================] - 7s 2ms/sample - loss: 0.0079 - acc: 0.9977 - val_loss: 0.7219 - val_acc: 0.8478\n",
      "Epoch 20/20\n",
      "3837/3837 [==============================] - 7s 2ms/sample - loss: 0.0053 - acc: 0.9995 - val_loss: 0.7962 - val_acc: 0.8548\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2893,
     "status": "ok",
     "timestamp": 1569760686357,
     "user": {
      "displayName": "D Meirong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDiaGPg7iox3RNjLk5fsQm8ZIF3UAOud5pIvPtjyg=s64",
      "userId": "16646563330135327635"
     },
     "user_tz": -480
    },
    "id": "QvDc5pslUCGw",
    "outputId": "1bd41b1b-29a7-4cca-96b8-0449cc3cf014"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.9454756856188108\n",
      "Test accuracy: 0.8406748\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5-aueAqqlUZ7"
   },
   "source": [
    "<h2> Data Augmentation </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IkzJeIhclgub"
   },
   "source": [
    "This section tests the usefulness of data augmentation in reducing overfitting. \n",
    "\n",
    "Data augmentation takes the approach of generating more training data from existing training samples, by augmenting the samples via a number of random transformations that yield believable-looking images. The goal is that at training time, the model will never see the exact same picture twice. This helps expose the model to more aspects of the data and generalize better.\n",
    "\n",
    "In Keras, this can be done by configuring a number of random transformations to be performed on the images read by the ImageDataGenerator instance.\n",
    "\n",
    "1. rotation_range is a value in degrees (0â€“180), a range within which to randomly rotate pictures.\n",
    "2. width_shift and height_shift are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally.\n",
    "3. shear_range is for randomly applying shearing transformations.\n",
    "4. zoom_range is for randomly zooming inside pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dwr_tDjNmVPW"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                               height_shift_range=0.08, zoom_range=0.08)\n",
    "\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "val_batches = gen.flow(X_val, y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 728
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 840353,
     "status": "ok",
     "timestamp": 1569761532248,
     "user": {
      "displayName": "D Meirong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDiaGPg7iox3RNjLk5fsQm8ZIF3UAOud5pIvPtjyg=s64",
      "userId": "16646563330135327635"
     },
     "user_tz": -480
    },
    "id": "l5TB7-2smyqw",
    "outputId": "3ef7bb9b-1c77-4ddf-98da-3664aff765c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "53/53 [==============================] - 48s 909ms/step - loss: 0.5339 - acc: 0.7542 - val_loss: 0.4056 - val_acc: 0.8187\n",
      "Epoch 2/20\n",
      "53/53 [==============================] - 44s 837ms/step - loss: 0.4245 - acc: 0.8153 - val_loss: 0.4229 - val_acc: 0.8163\n",
      "Epoch 3/20\n",
      "53/53 [==============================] - 40s 761ms/step - loss: 0.3907 - acc: 0.8300 - val_loss: 0.3442 - val_acc: 0.8471\n",
      "Epoch 4/20\n",
      "53/53 [==============================] - 41s 767ms/step - loss: 0.3546 - acc: 0.8442 - val_loss: 0.3715 - val_acc: 0.8335\n",
      "Epoch 5/20\n",
      "53/53 [==============================] - 41s 771ms/step - loss: 0.3496 - acc: 0.8544 - val_loss: 0.3863 - val_acc: 0.8446\n",
      "Epoch 6/20\n",
      "53/53 [==============================] - 41s 775ms/step - loss: 0.3374 - acc: 0.8578 - val_loss: 0.3205 - val_acc: 0.8533\n",
      "Epoch 7/20\n",
      "53/53 [==============================] - 41s 772ms/step - loss: 0.3457 - acc: 0.8551 - val_loss: 0.3434 - val_acc: 0.8533\n",
      "Epoch 8/20\n",
      "53/53 [==============================] - 41s 771ms/step - loss: 0.3434 - acc: 0.8504 - val_loss: 0.3363 - val_acc: 0.8508\n",
      "Epoch 9/20\n",
      "53/53 [==============================] - 40s 762ms/step - loss: 0.3145 - acc: 0.8643 - val_loss: 0.3152 - val_acc: 0.8582\n",
      "Epoch 10/20\n",
      "53/53 [==============================] - 47s 885ms/step - loss: 0.3105 - acc: 0.8734 - val_loss: 0.3273 - val_acc: 0.8545\n",
      "Epoch 11/20\n",
      "53/53 [==============================] - 43s 805ms/step - loss: 0.3022 - acc: 0.8685 - val_loss: 0.3445 - val_acc: 0.8483\n",
      "Epoch 12/20\n",
      "53/53 [==============================] - 41s 775ms/step - loss: 0.3020 - acc: 0.8755 - val_loss: 0.3329 - val_acc: 0.8656\n",
      "Epoch 13/20\n",
      "53/53 [==============================] - 41s 774ms/step - loss: 0.2882 - acc: 0.8763 - val_loss: 0.3104 - val_acc: 0.8619\n",
      "Epoch 14/20\n",
      "53/53 [==============================] - 41s 771ms/step - loss: 0.2908 - acc: 0.8806 - val_loss: 0.3421 - val_acc: 0.8545\n",
      "Epoch 15/20\n",
      "53/53 [==============================] - 41s 771ms/step - loss: 0.2828 - acc: 0.8774 - val_loss: 0.3580 - val_acc: 0.8508\n",
      "Epoch 16/20\n",
      "53/53 [==============================] - 41s 772ms/step - loss: 0.2654 - acc: 0.8917 - val_loss: 0.3040 - val_acc: 0.8755\n",
      "Epoch 17/20\n",
      "53/53 [==============================] - 41s 769ms/step - loss: 0.2814 - acc: 0.8809 - val_loss: 0.3383 - val_acc: 0.8619\n",
      "Epoch 18/20\n",
      "53/53 [==============================] - 40s 764ms/step - loss: 0.2829 - acc: 0.8777 - val_loss: 0.3379 - val_acc: 0.8594\n",
      "Epoch 19/20\n",
      "53/53 [==============================] - 45s 844ms/step - loss: 0.2519 - acc: 0.8955 - val_loss: 0.3042 - val_acc: 0.8718\n",
      "Epoch 20/20\n",
      "53/53 [==============================] - 41s 765ms/step - loss: 0.2439 - acc: 0.9006 - val_loss: 0.3379 - val_acc: 0.8693\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit_generator(batches, steps_per_epoch=3411//64, epochs=20,\n",
    "                    validation_data=val_batches, validation_steps=853//64, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3008,
     "status": "ok",
     "timestamp": 1569768766463,
     "user": {
      "displayName": "D Meirong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDiaGPg7iox3RNjLk5fsQm8ZIF3UAOud5pIvPtjyg=s64",
      "userId": "16646563330135327635"
     },
     "user_tz": -480
    },
    "id": "IfjGCgAmrVti",
    "outputId": "b55c8627-f00f-4eaa-ba42-0059e3eafc1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3548360028441196\n",
      "Test accuracy: 0.8781631\n"
     ]
    }
   ],
   "source": [
    "score1 = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score1[0])\n",
    "print('Test accuracy:', score1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DKci10GRrhVq"
   },
   "source": [
    "<h2> Results </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5_zU_zRPuUza"
   },
   "outputs": [],
   "source": [
    "#plot graphs to interpret the results (before data augmentation)\n",
    "\n",
    "accuracy_org = history.history['acc']\n",
    "val_accuracy_org = history.history['val_acc']\n",
    "loss_org = history.history['loss']\n",
    "val_loss_org = history.history['val_loss']\n",
    "epochs_org = range(len(accuracy_org))\n",
    "\n",
    "plt.plot(epochs_org, accuracy_org, 'bo', label='Training accuracy (before data augmentation)')\n",
    "plt.plot(epochs_org, val_accuracy_org, 'b', label='Validation accuracy (before data augmentation)')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs_org, loss_org, 'bo', label='Training loss (before data augmentation)')\n",
    "plt.plot(epochs_org, val_loss_org, 'b', label='Validation loss (before data augmentation)')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O10Evkgore7t"
   },
   "outputs": [],
   "source": [
    "#plot graphs to interpret the results (after data augmentation)\n",
    "\n",
    "accuracy = history1.history['acc']\n",
    "val_accuracy = history1.history['val_acc']\n",
    "loss = history1.history['loss']\n",
    "val_loss = history1.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "105E68jCwamy"
   },
   "source": [
    "<p> Data Augumentation reduces overfitting </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7hH0PUi3r1zX"
   },
   "source": [
    "<h2> Classification Results </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2955,
     "status": "ok",
     "timestamp": 1569781574675,
     "user": {
      "displayName": "D Meirong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDiaGPg7iox3RNjLk5fsQm8ZIF3UAOud5pIvPtjyg=s64",
      "userId": "16646563330135327635"
     },
     "user_tz": -480
    },
    "id": "3fPhaizMryxw",
    "outputId": "34d628bd-cf1c-416c-ea3e-78233c36ae84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy (on testing dataset): 87.82%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      flower     0.8876    0.8172    0.8509       454\n",
      "  non-flower     0.8721    0.9233    0.8970       613\n",
      "\n",
      "    accuracy                         0.8782      1067\n",
      "   macro avg     0.8798    0.8703    0.8740      1067\n",
      "weighted avg     0.8787    0.8782    0.8774      1067\n",
      "\n",
      "[[371  83]\n",
      " [ 47 566]]\n"
     ]
    }
   ],
   "source": [
    "# Make classification on the test dataset\n",
    "predicts    = model.predict(X_test)\n",
    "\n",
    "# Prepare the classification output\n",
    "# for the classification report\n",
    "predout     = np.argmax(predicts,axis=1)\n",
    "testout     = np.argmax(y_test,axis=1)\n",
    "\n",
    "# the labels for the classfication report\n",
    "labelname   = ['flower', 'non-flower']\n",
    "\n",
    "\n",
    "testScores  = metrics.accuracy_score(testout,predout)\n",
    "confusion   = metrics.confusion_matrix(testout,predout)\n",
    "\n",
    "\n",
    "print(\"Best accuracy (on testing dataset): %.2f%%\" % (testScores*100))\n",
    "print(metrics.classification_report(testout,predout,target_names=labelname,digits=4))\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d672jULixeUu"
   },
   "source": [
    "<p> Dropout is a regularization technique, and is most effective at preventing overfitting. <b> However, there are several places when dropout can hurt performance.</b>\n",
    " \n",
    "1.   Right before the last layer. This is generally a bad place to apply dropout, because the network has no ability to \"correct\" errors induced by dropout before the classification happens. <br>\n",
    "  \n",
    "2.   When the network is small relative to the dataset, regularization is usually unnecessary. If the model capacity is already low, lowering it further by adding regularization will hurt performance. I noticed most of your networks were relatively small and shallow. <br>\n",
    "  \n",
    "3.  When training time is limited.Usually dropout hurts performance at the start of training, but results in the final ''converged'' error being lower. Therefore, if we don't plan to train until convergence, you may not want to use dropout.  </p>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "2.3 CNN_Base_dropout.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
